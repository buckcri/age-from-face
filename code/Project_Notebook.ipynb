{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age from face\n",
    "\n",
    "Predict age of a person from an image of their face. As a training dataset we used a datasat available from Kaggle which uses portrait images from IMDB for which the age of persons is known. We try several approaches for age classification using Keras to define deep neural networks includung both classification and regression. From the neural network toolbox we use the so-called Adam optimizer, dropout regularization and batch normalization.\n",
    "\n",
    "According to Han & Otto (\"Age-Estimation from Face Images: Human vs. Machine Performance\", see below) the Bayes Error for this task is larger than 5, i.e. an absolute mean derivation of age estimation from facial images is expected when the task is perfomed by trained humans. One of the approaches tried out achieve a similar performance, but seem to overfit the training data.\n",
    "\n",
    "To illustrate the fact that the task is not easy for humans, we close with an interactive part where the user can conpare his or her own estimation against both the predicted age and the actual age of a person.\n",
    "\n",
    "Note that the actual data is not contained in the repository but needs to be downloaded separately from Kaggle - the link can be found at the bottom of this page under \"Additional Links\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Repo \n",
    "https://github.com/buckcri/age-from-face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants:\n",
    "Oskar Lachnit, Florian Diedrich, Nils-Christian Buck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course and Semester\n",
    "Deep Learning from Scratch, WiSe2122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "This work is licensed under the AGPL-3.0 Licence, please see the following link.\n",
    "\n",
    "https://www.gnu.org/licenses/agpl-3.0.en.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the Python environment has to be set up and the available data have to be made accessible. Fortunately, conversion of data which is already classifed in the file system is possible via a helper function defined in Keras. The fourth\n",
    "cell defines two helper functions for visualization and evaluation which are not important right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that we deleted folders for age larger than 93 because there were fee files, but gaps (e.g. no 94 old persons);\n",
    "#afterwards class label is equal to index in prediction array\n",
    "\n",
    "data_dir = \"../data/face_age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots two sequences with labels to visualize development over time\n",
    "def plot(num_epochs, first_seq, first_label, second_seq, second_label, title):\n",
    "    plt.plot(num_epochs, first_seq, label = first_label)\n",
    "    plt.plot(num_epochs, second_seq, label = second_label)\n",
    "    plt.legend(loc=0)\n",
    "    plt.xticks(num_epochs)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "#Returns the average of the top k (default: k=5) best predictions' index (index equals age in our case)\n",
    "def mean_avg_top_k(predictions, k=5):\n",
    "    pred_index_list = sorted(((value, key) for (key,value) in enumerate(predictions[0])), reverse=True)\n",
    "    sorted_index_pred_list = list([(key,value) for value,key in pred_index_list])\n",
    "\n",
    "    avg = 0\n",
    "    for i in range(k):\n",
    "        key, value = sorted_index_pred_list[i]\n",
    "        avg += key\n",
    "    avg /= k\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell does the first call to Keras. No that, depending on our execution context, a notification may bo shown that Tensorflow will be using CPU instruction instead of GPU instructions. This is normal and not considered as to be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "fixed_seed = 42 #Fix seed to achieve determinism\n",
    "\n",
    "validation_split = 0.1 #10% of data reserved for validation set\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory( #Load load training set; shuffeled by default\n",
    "  data_dir,\n",
    "  validation_split=validation_split,\n",
    "  subset = \"training\",\n",
    "  seed = fixed_seed,\n",
    "  image_size = (100, 100),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(   #Load validation set; shuffeled by default\n",
    "  data_dir,\n",
    "  validation_split = validation_split,\n",
    "  subset = \"validation\",\n",
    "  seed = fixed_seed,\n",
    "  image_size = (100, 100),\n",
    "  batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see whether the import has worked a single image together with its label is selected and shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = train_ds.take(1) #Show one random image from dataset, including label\n",
    "\n",
    "x, y = iter(example_batch).get_next() #x and y are one batch array of examples and labels\n",
    "\n",
    "example_image = x[0]\n",
    "example_label = y[0]\n",
    "\n",
    "plt.imshow(example_image.numpy().astype(\"uint8\"))\n",
    "plt.title(example_label.numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To additionally check the import the shape of the the picture data and the labels is shown. Next, we can visualize the number of samples for each category and the number of distict labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict #Count the number of examples for each label\n",
    "\n",
    "age_dist = defaultdict(int)\n",
    "\n",
    "for x_batch,y_batch in train_ds.as_numpy_iterator():\n",
    "   for i in range(len(y_batch)):\n",
    "       age_dist[y_batch[i]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(age_dist.keys()), age_dist.values()) #Plot above count\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('#Examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(list(age_dist.keys())) #Number of distinct labels:\n",
    "\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction via Classification (One Class per Age)\n",
    "\n",
    "For the first approach we define a neural network which should predict the age via classification. Each possible label is considered a class. The loss is defined accordingly. As the output is a probability distribution, it is possible to investigate\n",
    "the most likely assignments (as opposed to the third approach, where we aim at directly predicting a continuous value).\n",
    "\n",
    "First we define a basic model without dropout and batch normalization; both is added in a second step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DNN with hidden layers. Rescale pixel values to [0, 1] first.\n",
    "# There's one output class for each label.\n",
    "# @see https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n",
    "num_classes = num_labels\n",
    "\n",
    "#Do not define activation function on output layer as recommended by TF documentation.\n",
    "#Activation from using from_logits=True in loss function may offer better numerical stability.\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1.0 / 255),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "#SparseCategoricalCrossentropy is to be used with integer labels (versus one-hot representation)\n",
    "model.compile(\n",
    "  optimizer = 'adam',\n",
    "  loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train the network. Please note the comments in the next cell; on slower machines, the training may take longer than one hour. A small value can be used for a rough test of the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "epochs = 2 # 50 # (50 is the desired value, 2 is just for faster testing)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell visualizes the development of the accuracy and the loss on both the training data and the validation data during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "num_epochs = range(len(accuracy))\n",
    "\n",
    "plot(num_epochs, accuracy, 'Accuracy Train', val_accuracy, 'Accuracy Validation', 'Train and Validation accuracy')\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plot(num_epochs, loss, 'Loss Train', val_loss, 'Loss Validation', 'Train and Validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell visualizes 9 random images from the dataset together with the real age, the predicted age and an average of\n",
    "the 5 most probable ages according to the generated classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show one random image from dataset, including label\n",
    "example_batch = val_ds.take(1)\n",
    "\n",
    "#x and y are one batch array of examples and labels\n",
    "x,y = iter(example_batch).get_next()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(y[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Real\")\n",
    "    \n",
    "plt.show()    \n",
    "    \n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    predictions = model.predict(np.expand_dims(x[i], axis=0))\n",
    "    best_prediction = np.argmax(predictions)\n",
    "    #No need to map prediction index to label, because they are identical in our case\n",
    "    plt.title(best_prediction)\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Predicted (argmax)\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    predictions = model.predict(np.expand_dims(x[i], axis=0))\n",
    "    avg = mean_avg_top_k(predictions)\n",
    "    plt.title(avg)\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Predicted (top 5)\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions for last example:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we take the same approach as before but add dropout normalization and batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DNN with hidden layers. Rescale pixel values to [0, 1] first.\n",
    "# There's one output class for each label.\n",
    "# @see https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n",
    "num_classes = num_labels\n",
    "\n",
    "dropout_rate = 0.25\n",
    "\n",
    "#Do not define activation function on output layer as recommended by TF documentation.\n",
    "#Activation from using from_logits=True in loss function may offer better numerical stability.\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1.0 / 255),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(dropout_rate),\n",
    "  tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(dropout_rate),\n",
    "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "#SparseCategoricalCrossentropy is to be used with integer labels (versus one-hot representation)\n",
    "model.compile(\n",
    "  optimizer = 'adam',\n",
    "  loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "epochs = 2 # 60 # (60 is the desired value, 2 is just for faster testing)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data = val_ds,\n",
    "  epochs = epochs\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "num_epochs = range(len(accuracy))\n",
    "\n",
    "plot(num_epochs, accuracy, 'Accuracy Train', val_accuracy, 'Accuracy Validation', 'Train and Validation accuracy')\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plot(num_epochs, loss, 'Loss Train', val_loss, 'Loss Validation', 'Train and Validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show one random image from dataset, including label\n",
    "\n",
    "example_batch = val_ds.take(1)\n",
    "\n",
    "#x and y are one batch array of examples and labels\n",
    "x,y = iter(example_batch).get_next()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(y[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Real\")\n",
    "    \n",
    "plt.show()    \n",
    "    \n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    predictions = model.predict(np.expand_dims(x[i], axis = 0))\n",
    "    best_prediction = np.argmax(predictions)\n",
    "    #No need to map prediction index to label, because they are identical in our case\n",
    "    plt.title(best_prediction)\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Predicted (argmax)\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    predictions = model.predict(np.expand_dims(x[i], axis = 0))\n",
    "    avg = mean_avg_top_k(predictions)\n",
    "    plt.title(avg)\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Predicted (top k)\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction via Classification (One Class per Age Group)\n",
    "\n",
    "The approach in this section also tries to predict the age by assignment to a class similar as before, but the data is remapped to a coarser partition of the age range. More precisely, each age is rounded down to the next smaller or equal age divisible by ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of years to group together\n",
    "\n",
    "age_grouping = 10\n",
    "\n",
    "def label_group_mapping(x, y):\n",
    "    return x, y // age_grouping\n",
    "\n",
    "train_ds_grouped = train_ds.map(label_group_mapping)\n",
    "val_ds_grouped = val_ds.map(label_group_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DNN with hidden layers. Rescale pixel values to [0, 1] first.\n",
    "num_classes = num_labels//age_grouping\n",
    "if ((num_labels % age_grouping) != 0):\n",
    "    num_classes += 1\n",
    "\n",
    "print(f\"Grouped {num_labels} labels to {num_classes} classes with stride {age_grouping}.\")\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "#Do not define activation function on output layer as recommended by TF documentation.\n",
    "#Activation from using from_logits=True in loss function may offer better numerical stability.\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1.0 / 255),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(dropout_rate),\n",
    "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(dropout_rate),\n",
    "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "#SparseCategoricalCrossentropy is to be used with integer labels (versus one-hot representation)\n",
    "model.compile(\n",
    "  optimizer = 'adam',\n",
    "  loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "epochs = 2 # 30 # (30 is the desired value, 2 is just for faster testing)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds_grouped,\n",
    "  validation_data = val_ds_grouped,\n",
    "  epochs = epochs\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "num_epochs = range(len(accuracy))\n",
    "\n",
    "plot(num_epochs, accuracy, 'Accuracy Train', val_accuracy, 'Accuracy Validation', 'Train and Validation accuracy')\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plot(num_epochs, loss, 'Loss Train', val_loss, 'Loss Validation', 'Train and Validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grouped_age_range(age_class):\n",
    "    lower_bound = age_class * age_grouping\n",
    "    upper_bound = ( (age_class + 1) * age_grouping) - 1\n",
    "    return \"{} ({}-{})\".format(age_class, lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show one random image from dataset, including label\n",
    "example_batch = val_ds_grouped.take(1)\n",
    "\n",
    "#x and y are one batch array of examples and labels\n",
    "x,y = iter(example_batch).get_next()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(to_grouped_age_range(y[i].numpy()))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Real\")\n",
    "    \n",
    "plt.show()    \n",
    "    \n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    predictions = model.predict(np.expand_dims(x[i], axis=0))\n",
    "    best_prediction = np.argmax(predictions)\n",
    "    plt.title(to_grouped_age_range(best_prediction))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Predicted (argmax)\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Predictions for last example:\")\n",
    "print(predictions)\n",
    "print(best_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction via Regression\n",
    "\n",
    "As a third approach we can try to predict the age not by classification but as a single value. Intuitively this should permit to take into account that numerically similar ages are in fact similar permitted predictions; this is impossible using the two categorial apporoaches presented above.\n",
    "\n",
    "In a first step, the dataset is remapped to use a float as a label type in order to permit scalar evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize life to a supposed lifespan of 100 years\n",
    "\n",
    "def label_age_normalization(x, y):\n",
    "    return x, tf.cast(y, tf.float32) / 100.0\n",
    "\n",
    "# Remap data set\n",
    "\n",
    "train_ds_age_normalized = train_ds.map(label_age_normalization)\n",
    "val_ds_age_normalized = val_ds.map(label_age_normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a neural network is defined which is very similar to the ones before; however, there is finally only one output node as not a probability distribution but a single is desired as an oputput. Consequently, the loss is calculated via the mean squared error, as opposed to a loss which is suitable for assignment of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.1\n",
    "\n",
    "#Do not define activation function on output layer as recommended by TF documentation.\n",
    "#Activation from using from_logits=True in loss function may offer better numerical stability.\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(dropout_rate),\n",
    "  tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dropout(dropout_rate),\n",
    "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(1, activation = 'relu')\n",
    "])\n",
    "\n",
    "#SparseCategoricalCrossentropy is to be used with integer labels (versus one-hot representation)\n",
    "model.compile(\n",
    "  optimizer = 'adam',\n",
    "  loss = tf.losses.MeanSquaredError(),\n",
    "  metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the two previous approaches, the network needs to be trained. Please note the comment again, a smaller value\n",
    "is suitable only to check whether the network can be trained in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "\n",
    "epochs = 2 # 30 # (30 is the desired value, 2 is just for faster testing)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds_age_normalized,\n",
    "  validation_data = val_ds_age_normalized,\n",
    "  epochs = epochs\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize progress of training\n",
    "\n",
    "loss = history.history['loss']\n",
    "num_epochs = range(len(loss))\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plot(num_epochs, loss, 'Loss Train', val_loss, 'Loss Validation', 'Train and Validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show one random image from dataset, including label\n",
    "\n",
    "example_batch = val_ds_age_normalized.take(1)\n",
    "\n",
    "#x and y are one batch array of examples and labels\n",
    "x,y = iter(example_batch).get_next()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(round(y[i].numpy(), 2))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Real\")\n",
    "    \n",
    "plt.show()    \n",
    "    \n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x[i].numpy().astype(\"uint8\"))\n",
    "    predictions = model.predict(np.expand_dims(x[i], axis=0))\n",
    "    plt.title(round(predictions[0][0], 2))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Predicted\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Part for Regression\n",
    "\n",
    "In this part, a random picture from the validation data is selected. It is then presented to the user who can guess the age of the person shown. Afterwards, the predicted age of the person is shown. Finally, it is revealed how old the person acutally is based on the ground truth.\n",
    "\n",
    "For the interaction, the upper cell needs to be executed only once to do some technical preparation. The lower cell can be executed repeatedly, but note that you need to actually reveal the real age, as otherwise the cell cannot be restarted as its execution is not finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define helper function for showing picture and title, setup constants\n",
    "\n",
    "example_age_prompt = \"Let's Guess the age!\"\n",
    "keyboard_prompt = \"Please press return.\"\n",
    "\n",
    "def show_picture(picture, title):\n",
    "    plt.imshow(picture.numpy().astype(\"uint8\"))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select one random image from dataset and generate prediction; on execution, every prompt for pressing return\n",
    "#must be met, otherwise the cell does not terminate and cannot be restarted properly\n",
    "\n",
    "example_batch = val_ds_age_normalized.take(1)\n",
    "\n",
    "random_x,random_y = iter(example_batch).get_next()\n",
    "\n",
    "example_image = random_x[0]\n",
    "example_age_real = round(random_y[0].numpy(), 2)\n",
    "example_age_predicted = round(model.predict(np.expand_dims(example_image, axis=0))[0][0], 2)\n",
    "\n",
    "clear_output(wait = True)\n",
    "show_picture(example_image, example_age_prompt)    #Show image with prompt\n",
    "input(keyboard_prompt)\n",
    "\n",
    "clear_output(wait = True)\n",
    "show_picture(example_image, example_age_predicted) #Show image with predicted age\n",
    "input(keyboard_prompt)\n",
    "\n",
    "clear_output(wait = True)\n",
    "show_picture(example_image, example_age_real)      #Show image with real age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "* S. N. Kohail:  \n",
    "Using Artificial Neural Network for Human Age Estimation Based on Facial Images  \n",
    "2012 International Conference on Innovations in Information Technology (IIT)  \n",
    "https://www.inf.uni-hamburg.de/en/inst/ab/lt/people/alumni/sarah-kohail/kohail-age-estimation.pdf\n",
    "\n",
    "* Z. Qawaqneh, A. Abu Mallouh & B. D. Barkana:  \n",
    "Deep Convolutional Neural Network for Age Estimation based on VGG-Face Model  \n",
    "https://arxiv.org/ftp/arxiv/papers/1709/1709.01664.pdf\n",
    "\n",
    "* N. Hewahi, A. Olwan, N. Tubeel, S. El-Asar, Z. Abu-Sultan:  \n",
    "Age Estimation based on Neural Networks using Face Features  \n",
    "Journal of Emerging Trends in Computing and Information Sciences 1:2, October 2010  \n",
    "https://www.researchgate.net/publication/47277288_Age_Estimation_based_on_Neural_Networks_using_Face_Features\n",
    "\n",
    "* R. Rahadian & S. Suyanto:  \n",
    "Deep Residual Neural Network for Age Classification with Face Image  \n",
    "2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)  \n",
    "https://ieeexplore.ieee.org/document/9034664\n",
    "\n",
    "* M. M. Islam & J.-H. Baek:  \n",
    "Deep Learning Based Real Age and Gender Estimation from Unconstrained Face Image towards Smart Store Customer Relationship Management  \n",
    "Applied Sciences 2021, 11  \n",
    "https://www.mdpi.com/2076-3417/11/10/4549/pdf\n",
    "\n",
    "* A. Othmania, A. R. Taleb, H. Abdelkawy & A. Hadid:  \n",
    "Age estimation from faces using deep learning: A comparative analysis  \n",
    "Computer Vision and Image Understanding 196, July 2020  \n",
    "https://www.sciencedirect.com/science/article/abs/pii/S1077314220300424\n",
    "\n",
    "* H. Han & C. Otto:\n",
    "Age Estimation from Face Images: Human vs. Machine Performance\n",
    "International Conference on Biometrics\n",
    "https://www.researchgate.net/publication/235701854_Age_Estimation_from_Face_Images_Human_vs_Machine_Performance\n",
    "\n",
    "Additional Links:\n",
    "\n",
    "* https://towardsdatascience.com/age-detection-using-facial-images-traditional-machine-learning-vs-deep-learning-2437b2feeab2\n",
    "\n",
    "* https://www.kaggle.com/frabbisw/facial-age"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
